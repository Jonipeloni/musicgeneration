{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jonipeloni/musicgeneration/blob/main/Untitled12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-ltajF1jEc5",
        "outputId": "72a236f7-d301-4205-8667-240de8dd844c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting miditok\n",
            "  Downloading miditok-3.0.2-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from miditok) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from miditok) (1.25.2)\n",
            "Collecting symusic>=0.3.2 (from miditok)\n",
            "  Downloading symusic-0.4.5-cp310-cp310-manylinux_2_28_x86_64.manylinux_2_27_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from miditok) (0.15.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from miditok) (4.66.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->miditok) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->miditok) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->miditok) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->miditok) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->miditok) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->miditok) (24.0)\n",
            "Collecting pySmartDL (from symusic>=0.3.2->miditok)\n",
            "  Downloading pySmartDL-1.3.4-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from symusic>=0.3.2->miditok) (4.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.16.4->miditok) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.16.4->miditok) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.16.4->miditok) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.16.4->miditok) (2024.2.2)\n",
            "Installing collected packages: pySmartDL, symusic, miditok\n",
            "Successfully installed miditok-3.0.2 pySmartDL-1.3.4 symusic-0.4.5\n"
          ]
        }
      ],
      "source": [
        "!pip install miditok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pretty_midi numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB8FChu_jj0_",
        "outputId": "9a221f62-ed9c-4fe7-aa09-092a10dee4f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Downloading mido-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n",
            "Collecting packaging~=23.1 (from mido>=1.1.16->pretty_midi)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592289 sha256=54d500d06a99d412e01c3151f3ab8edc411f52fe049765594d9931e0f1252c45\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: packaging, mido, pretty_midi\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed mido-1.3.2 packaging-23.2 pretty_midi-0.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgTlXgnieCfr",
        "outputId": "7849340c-8fc8-427c-94f8-ca35062a54c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pretty_midi\n",
        "\n",
        "import collections\n",
        "#import datetime\n",
        "#import fluidsynth\n",
        "#import glob\n",
        "#import numpy as np\n",
        "import pathlib\n",
        "#import pandas as pd\n",
        "#import pretty_midi\n",
        "#import seaborn as sns\n",
        "#import tensorflow as tf\n",
        "from miditok import REMI\n"
      ],
      "metadata": {
        "id": "bRO_e6nRjfvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Data\n",
        "data_dir = pathlib.Path('data/maestro-v2.0.0')\n",
        "if not data_dir.exists():\n",
        "  tf.keras.utils.get_file(\n",
        "      'maestro-v2.0.0-midi.zip',\n",
        "      origin='https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip',\n",
        "      extract=True,\n",
        "      cache_dir='.', cache_subdir='data',\n",
        "  )"
      ],
      "metadata": {
        "id": "2CH_AUwejTgg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec5a23d2-ce2f-402a-a135-c361d20574bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip\n",
            "59243107/59243107 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shrinking amount of Files\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "subdirectories = [\"2006\", \"2008\", \"2009\", \"2011\", \"2013\", \"2014\", \"2015\", \"2017\", \"2018\"]\n",
        "for a in subdirectories:\n",
        "\n",
        "  directory_to_delete = data_dir / a\n",
        "\n",
        "  # Delete the directory and all its contents\n",
        "  try:\n",
        "      shutil.rmtree(directory_to_delete)\n",
        "      print(f\"Deleted {directory_to_delete}\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error deleting {directory_to_delete}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5zlvti1j8dN",
        "outputId": "71d2b6fc-90f9-44dc-e6f8-0541a4677265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted data/maestro-v2.0.0/2006\n",
            "Deleted data/maestro-v2.0.0/2008\n",
            "Deleted data/maestro-v2.0.0/2009\n",
            "Deleted data/maestro-v2.0.0/2011\n",
            "Deleted data/maestro-v2.0.0/2013\n",
            "Deleted data/maestro-v2.0.0/2014\n",
            "Deleted data/maestro-v2.0.0/2015\n",
            "Deleted data/maestro-v2.0.0/2017\n",
            "Deleted data/maestro-v2.0.0/2018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folders = [\"2004\"]\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(data_dir, folder)\n",
        "\n",
        "    # Check if the folder exists\n",
        "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
        "        for filename in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "            # Check if it is a file and not a sub-directory\n",
        "            if os.path.isfile(file_path):\n",
        "                # Move file\n",
        "                shutil.move(file_path, data_dir)\n",
        "\n",
        "        # Remove the now-empty folder\n",
        "        os.rmdir(folder_path)"
      ],
      "metadata": {
        "id": "wHCTH1oIkDf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pretty_midi\n",
        "\n",
        "midi_files_dir = data_dir\n",
        "output_dir = \"selected_midi_files\"  # Define the output directory\n",
        "output_path = os.path.join(midi_files_dir, output_dir)\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "# Criteria for selection\n",
        "desired_time_signature = (4, 4)  # (numerator, denominator)\n",
        "min_length_seconds = 100\n",
        "max_length_seconds = 800\n",
        "\n",
        "selected_files = []\n",
        "\n",
        "# Iterate over all files in the directory\n",
        "for filename in os.listdir(midi_files_dir):\n",
        "    if filename.endswith('.mid') or filename.endswith('.midi'):  # Check if it's a MIDI file\n",
        "        file_path = os.path.join(midi_files_dir, filename)\n",
        "\n",
        "        try:\n",
        "            # Load the MIDI file\n",
        "            midi_data = pretty_midi.PrettyMIDI(file_path)\n",
        "\n",
        "            # Check time signatures\n",
        "            time_signatures = midi_data.time_signature_changes\n",
        "            has_desired_time_signature = any(ts.numerator == desired_time_signature[0] and\n",
        "                                             ts.denominator == desired_time_signature[1]\n",
        "                                             for ts in time_signatures)\n",
        "\n",
        "            # Check length\n",
        "            length = midi_data.get_end_time()  # This returns the length in seconds\n",
        "            if has_desired_time_signature and min_length_seconds <= length <= max_length_seconds:\n",
        "                # Construct output file path\n",
        "                output_file_path = os.path.join(output_path, filename)\n",
        "                # Copy the file to the output directory\n",
        "                os.rename(file_path, output_file_path)\n",
        "                selected_files.append(output_file_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "# Print or use the selected files\n",
        "for file in selected_files:\n",
        "    print(file)\n"
      ],
      "metadata": {
        "id": "RQAaeIpGkMWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97bb987c-9fdb-407c-8cbd-f47a2d8d47a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_06_R2_2004_01_ORIG_MID--AUDIO_06_R2_2004_01_Track01_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_10_R1_2004_03-04_ORIG_MID--AUDIO_10_R1_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_22_R2_2004_01_ORIG_MID--AUDIO_22_R2_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_10_R1_2004_01-02_ORIG_MID--AUDIO_10_R1_2004_01_Track01_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_01-03_ORIG_MID--AUDIO_17_R1_2004_02_Track02_wav--2.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_16_R2_2004_01_ORIG_MID--AUDIO_16_R2_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_13_01_2004_01-05_ORIG_MID--AUDIO_13_R1_2004_10_Track10_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_16_R2_2004_01_ORIG_MID--AUDIO_16_R2_2004_04_Track04_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_12_01_2004_01-05_ORIG_MID--AUDIO_12_R1_2004_08_Track08_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_01_R1_2004_01-02_ORIG_MID--AUDIO_01_R1_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_16_R1_2004_01-08_ORIG_MID--AUDIO_16_R1_2004_04_Track04_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_12_01_2004_01-05_ORIG_MID--AUDIO_12_R1_2004_07_Track07_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_01-02_ORIG_MID--AUDIO_20_R2_2004_04_Track04_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_21_R1_2004_02_ORIG_MID--AUDIO_21_R1_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_11_R1_2004_03-04_ORIG_MID--AUDIO_11_R1_2004_04_Track04_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_13_01_2004_01-05_ORIG_MID--AUDIO_13_R1_2004_08_Track08_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_09_R1_2004_01-02_ORIG_MID--AUDIO_09_R1_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_08_Track08_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_16_R1_2004_01-08_ORIG_MID--AUDIO_16_R1_2004_05_Track05_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_03-06_ORIG_MID--AUDIO_20_R2_2004_12_Track12_wav--1.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_05_R1_2004_01_ORIG_MID--AUDIO_05_R1_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_06_R1_2004_02-03_ORIG_MID--AUDIO_06_R1_2004_05_Track05_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_19_R2_2004_01_ORIG_MID--AUDIO_19_R2_2004_01_Track01_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_10_Track10_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_04_R1_2004_03-05_ORIG_MID--AUDIO_04_R1_2004_05_Track05_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_14_R1_2004_04_ORIG_MID--AUDIO_14_R1_2004_06_Track06_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_15_R2_2004_01_ORIG_MID--AUDIO_15_R2_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_14_R1_2004_04_ORIG_MID--AUDIO_14_R1_2004_05_Track05_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_09_R1_2004_01-02_ORIG_MID--AUDIO_09_R1_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_13_01_2004_01-05_ORIG_MID--AUDIO_13_R1_2004_09_Track09_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_08_R1_2004_03_ORIG_MID--AUDIO_08_R1_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_03_R1_2004_01-02_ORIG_MID--AUDIO_03_R1_2004_01_Track01_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_22_R2_2004_01_ORIG_MID--AUDIO_22_R2_2004_04_Track04_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_07_R1_2004_01_ORIG_MID--AUDIO_07_R1_2004_06_Track06_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_14_R1_2004_04_ORIG_MID--AUDIO_14_R1_2004_04_Track04_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_04_R1_2004_06_ORIG_MID--AUDIO_04_R1_2004_08_Track08_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_04_R1_2004_03-05_ORIG_MID--AUDIO_04_R1_2004_04_Track04_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_22_R2_2004_01_ORIG_MID--AUDIO_22_R2_2004_01_Track01_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_09_R1_2004_01-02_ORIG_MID--AUDIO_09_R1_2004_01_Track01_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_21_R1_2004_02_ORIG_MID--AUDIO_21_R1_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_22_R1_2004_01-04_ORIG_MID--AUDIO_22_R1_2004_05_Track05_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_01-02_ORIG_MID--AUDIO_20_R2_2004_06_Track06_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_08_R1_2004_04-06_ORIG_MID--AUDIO_08_R1_2004_05_Track05_wav--2.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_04_R1_2004_01-02_ORIG_MID--AUDIO_04_R1_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_01_R1_2004_04-05_ORIG_MID--AUDIO_01_R1_2004_06_Track06_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_07_R1_2004_01_ORIG_MID--AUDIO_07_R1_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_14_R2_2004_01_ORIG_MID--AUDIO_14_R2_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_05_R1_2004_02-03_ORIG_MID--AUDIO_05_R1_2004_06_Track06_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_14_R2_2004_01_ORIG_MID--AUDIO_14_R2_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_16_R1_2004_01-08_ORIG_MID--AUDIO_16_R1_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_11_R1_2004_01-02_ORIG_MID--AUDIO_11_R1_2004_01_Track01_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_19_R1_2004_01-02_ORIG_MID--AUDIO_19_R1_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_13_01_2004_01-05_ORIG_MID--AUDIO_13_R1_2004_12_Track12_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_08_R1_2004_01-02_ORIG_MID--AUDIO_08_R1_2004_01_Track01_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_12_01_2004_01-05_ORIG_MID--AUDIO_12_R1_2004_09_Track09_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_19_R1_2004_01-02_ORIG_MID--AUDIO_19_R1_2004_01_Track01_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_08_R1_2004_04-06_ORIG_MID--AUDIO_08_R1_2004_04_Track04_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_06_R2_2004_01_ORIG_MID--AUDIO_06_R2_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_15_R2_2004_01_ORIG_MID--AUDIO_15_R2_2004_04_Track04_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_15_R2_2004_01_ORIG_MID--AUDIO_15_R2_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_04_R1_2004_03-05_ORIG_MID--AUDIO_04_R1_2004_06_Track06_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_01_R1_2004_04-05_ORIG_MID--AUDIO_01_R1_2004_05_Track05_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_07_R1_2004_01_ORIG_MID--AUDIO_07_R1_2004_12_Track12_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_14_R1_2004_01-03_ORIG_MID--AUDIO_14_R1_2004_01_Track01_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_16_R1_2004_01-08_ORIG_MID--AUDIO_16_R1_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_01-02_ORIG_MID--AUDIO_20_R2_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_19_R2_2004_01_ORIG_MID--AUDIO_19_R2_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_09_R1_2004_05_ORIG_MID--AUDIO_09_R1_2004_06_Track06_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_15_R2_2004_01_ORIG_MID--AUDIO_15_R2_2004_01_Track01_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_01_R1_2004_01-02_ORIG_MID--AUDIO_01_R1_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_17_R2_2004_01_ORIG_MID--AUDIO_17_R2_2004_01_Track01_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_01-03_ORIG_MID--AUDIO_17_R1_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_22_R2_2004_01_ORIG_MID--AUDIO_22_R2_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_06_Track06_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_16_R2_2004_01_ORIG_MID--AUDIO_16_R2_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_19_R2_2004_01_ORIG_MID--AUDIO_19_R2_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_01-03_ORIG_MID--AUDIO_17_R1_2004_02_Track02_wav--1.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_18_R1_2004_01-02_ORIG_MID--AUDIO_18_R1_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_15_R1_2004_01-02_ORIG_MID--AUDIO_15_R1_2004_01_Track01_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_09_R1_2004_05_ORIG_MID--AUDIO_09_R1_2004_08_Track08_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_04_ORIG_MID--AUDIO_17_R1_2004_11_Track11_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_08_R1_2004_04-06_ORIG_MID--AUDIO_08_R1_2004_05_Track05_wav--1.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_12_01_2004_01-05_ORIG_MID--AUDIO_12_R1_2004_10_Track10_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_17_R2_2004_01_ORIG_MID--AUDIO_17_R2_2004_04_Track04_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_11_R1_2004_03-04_ORIG_MID--AUDIO_11_R1_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_18_R1_2004_01-02_ORIG_MID--AUDIO_18_R1_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_17_R2_2004_01_ORIG_MID--AUDIO_17_R2_2004_02_Track02_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_01-03_ORIG_MID--AUDIO_17_R1_2004_06_Track06_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_16_R1_2004_01-08_ORIG_MID--AUDIO_16_R1_2004_06_Track06_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_17_R2_2004_01_ORIG_MID--AUDIO_17_R2_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_22_R1_2004_01-04_ORIG_MID--AUDIO_22_R1_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_18_R1_2004_01-02_ORIG_MID--AUDIO_18_R1_2004_04_Track04_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_18_R1_2004_01-02_ORIG_MID--AUDIO_18_R1_2004_05_Track05_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_06_R2_2004_01_ORIG_MID--AUDIO_06_R2_2004_03_Track03_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_03-06_ORIG_MID--AUDIO_20_R2_2004_08_Track08_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_14_R2_2004_01_ORIG_MID--AUDIO_14_R2_2004_04_Track04_wav.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_03-06_ORIG_MID--AUDIO_20_R2_2004_12_Track12_wav--2.midi\n",
            "data/maestro-v2.0.0/selected_midi_files/MIDI-Unprocessed_XP_09_R1_2004_05_ORIG_MID--AUDIO_09_R1_2004_07_Track07_wav.midi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from miditok import REMI\n",
        "from pathlib import Path\n",
        "\n",
        "# A validation method to discard MIDIs we do not want\n",
        "def midi_valid(midi) -> bool:\n",
        "    if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
        "        return False  # time signature different from 4/*, 4 beats per bar\n",
        "    if midi.max_tick < 10 * midi.ticks_per_beat:\n",
        "        return False  # this MIDI is too short\n",
        "    return True\n",
        "\n",
        "# Define the folder path without using BPE\n",
        "tokens_noBPE = data_dir / \"tokens_noBPE\"\n",
        "\n",
        "# Create the folder\n",
        "tokens_noBPE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Path to the MIDI files and the tokens\n",
        "path_midi_files = data_dir\n",
        "path_tokens_noBPE = data_dir / 'tokens_noBPE/'\n",
        "\n",
        "# Creates the tokenizer and lists the file paths\n",
        "tokenizer = REMI()\n",
        "midi_paths = selected_files # Make sure selected_files is defined and contains paths to your MIDI files\n",
        "\n",
        "# Converts MIDI files to tokens saved as JSON files\n",
        "tokenizer.tokenize_midi_dataset(\n",
        "    midi_paths,\n",
        "    Path(path_tokens_noBPE),\n",
        "    midi_valid\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_xZgJ-iP6Tq",
        "outputId": "200c5e34-8387-4f83-e41c-675a5a3acf1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokenizing MIDIs (maestro-v2.0.0/tokens_noBPE): 100%|██████████| 101/101 [00:09<00:00, 10.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "# Load the JSON file\n",
        "with open(\"/content/data/maestro-v2.0.0/tokens_noBPE/MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_06_Track06_wav.json\", \"r\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract the integers from the \"ids\" field\n",
        "ids = data[\"ids\"][0]\n",
        "\n",
        "# Print the extracted integers\n",
        "print(ids)\n",
        "\n",
        "# Convert integers to string\n",
        "text = \" \".join([str(i) for i in ids])\n",
        "\n",
        "# Initialize and train BPE tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "tokenizer.train_from_iterator([text])\n",
        "\n",
        "# Tokenize\n",
        "encoded = tokenizer.encode(text)\n",
        "\n",
        "# Decode\n",
        "decoded = tokenizer.decode(encoded.ids)\n",
        "\n",
        "print(encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqf2VRUGbtMq",
        "outputId": "f721a0ae-57f1-4d4c-b008-531c82221f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 206, 27, 103, 125, 15, 101, 125, 207, 28, 104, 125, 16, 101, 125, 208, 30, 106, 126, 18, 102, 125, 210, 32, 106, 134, 20, 102, 134, 4, 205, 37, 106, 152, 46, 110, 155, 40, 109, 152, 32, 104, 155, 4, 211, 38, 105, 127, 47, 106, 128, 212, 43, 105, 125, 28, 103, 128, 216, 44, 106, 132, 23, 105, 129, 32, 102, 132, 51, 107, 132, 39, 105, 130, 4, 210, 63, 103, 127, 44, 103, 128, 51, 102, 128, 56, 102, 125, 4, 213, 11, 107, 125, 214, 23, 103, 125, 215, 13, 104, 125, 216, 25, 107, 125, 15, 108, 126, 217, 27, 109, 126, 218, 16, 107, 125, 28, 109, 126, 219, 18, 109, 126, 220, 30, 111, 125, 4, 190, 20, 106, 134, 32, 110, 134, 214, 46, 113, 156, 215, 32, 106, 157, 37, 107, 155, 40, 109, 154, 4, 4, 192, 38, 105, 128, 47, 106, 129, 43, 105, 125, 28, 103, 128, 197, 44, 105, 131, 23, 105, 129, 32, 102, 131, 51, 106, 131, 39, 104, 128, 4, 190, 51, 102, 130, 63, 104, 127, 56, 102, 126, 44, 100, 128, 219, 8, 107, 127, 220, 20, 111, 126, 4, 190, 10, 106, 125, 22, 109, 126, 191, 11, 108, 125, 23, 110, 125, 192, 13, 110, 125, 193, 15, 107, 125, 25, 110, 125, 194, 27, 112, 125, 16, 112, 126, 195, 28, 112, 125, 196, 18, 114, 125, 30, 112, 125, 197, 20, 111, 126, 32, 113, 125, 199, 21, 115, 132, 33, 116, 133, 218, 48, 115, 143, 38, 114, 146, 33, 113, 145, 42, 114, 140, 4, 213, 30, 113, 125, 39, 113, 126, 49, 114, 129, 45, 112, 125, 218, 33, 114, 129, 52, 115, 131, 40, 115, 129, 25, 112, 128, 45, 113, 132, 4, 205, 25, 108, 152, 31, 108, 151, 206, 34, 110, 151, 207, 40, 116, 146, 43, 115, 144, 46, 114, 147, 55, 115, 148, 52, 113, 149, 4, 206, 25, 112, 126, 41, 113, 134, 32, 112, 126, 56, 114, 126, 35, 112, 126, 207, 47, 113, 126, 44, 114, 126, 53, 113, 126, 216, 40, 113, 163, 44, 112, 159, 56, 111, 160, 59, 113, 158, 50, 111, 158, 4, 4, 190, 42, 106, 131, 196, 43, 107, 132, 204, 39, 104, 134, 44, 104, 131, 205, 35, 104, 133, 56, 107, 133, 51, 103, 133, 4, 197, 56, 101, 130, 44, 101, 130, 63, 102, 130, 198, 51, 103, 129, 4, 200, 45, 109, 127, 201, 42, 105, 127, 203, 44, 111, 157, 204, 40, 107, 151, 4, 189, 51, 111, 142, 48, 106, 137, 220, 52, 108, 126, 4, 189, 37, 105, 128, 44, 102, 128, 49, 101, 125, 193, 36, 105, 130, 56, 107, 131, 44, 97, 128, 51, 104, 130, 28, 104, 129, 211, 52, 100, 126, 64, 107, 126, 48, 103, 126, 212, 55, 103, 127, 214, 51, 102, 132, 56, 106, 129, 63, 106, 128, 44, 98, 142, 4, 215, 45, 112, 127, 42, 108, 127, 217, 44, 111, 159, 218, 40, 107, 151, 4, 203, 51, 111, 144, 48, 107, 141, 4, 201, 52, 108, 126, 202, 39, 104, 126, 44, 105, 127, 49, 105, 126, 204, 37, 106, 127, 208, 36, 105, 130, 28, 104, 129, 56, 108, 131, 51, 106, 130, 44, 105, 128, 4, 195, 64, 105, 126, 48, 103, 127, 52, 100, 126, 196, 55, 103, 127, 199, 63, 105, 127, 56, 106, 125, 51, 101, 128, 44, 104, 129, 4, 198, 24, 110, 125, 20, 100, 125, 199, 22, 107, 127, 25, 111, 128, 200, 24, 105, 125, 27, 107, 125, 202, 28, 112, 125, 203, 30, 111, 125, 204, 26, 107, 125, 31, 112, 126, 205, 27, 110, 125, 32, 115, 131, 206, 28, 113, 131, 4, 192, 52, 114, 144, 40, 112, 138, 47, 110, 143, 38, 112, 144, 193, 23, 111, 141, 28, 108, 142, 32, 106, 142, 44, 106, 126, 195, 44, 96, 135, 219, 40, 112, 126, 25, 110, 125, 54, 114, 127, 45, 111, 125, 42, 111, 125, 30, 110, 125, 49, 111, 125, 33, 112, 125, 4, 194, 42, 110, 133, 56, 114, 133, 27, 109, 129, 51, 110, 132, 32, 109, 131, 36, 109, 132, 48, 111, 131, 44, 110, 129, 213, 63, 108, 127, 51, 105, 127, 44, 104, 129, 56, 106, 127, 4, 204, 57, 114, 132, 40, 111, 131, 25, 110, 130, 52, 112, 132, 45, 111, 130, 49, 111, 131, 33, 111, 131, 30, 111, 131, 4, 189, 42, 112, 133, 59, 115, 134, 27, 111, 132, 54, 113, 134, 32, 111, 132, 47, 112, 131, 51, 111, 132, 35, 111, 133, 204, 28, 107, 126, 34, 110, 126, 37, 112, 126, 61, 115, 127, 205, 49, 114, 126, 52, 114, 126, 56, 112, 126, 44, 113, 126, 206, 59, 96, 125, 210, 30, 113, 126, 45, 115, 126, 63, 115, 126, 39, 108, 126, 54, 114, 126, 57, 113, 127, 36, 112, 126, 51, 115, 126, 217, 37, 111, 133, 218, 47, 114, 136, 32, 112, 131, 40, 112, 134, 59, 115, 136, 64, 116, 138, 52, 116, 132, 56, 113, 133, 4, 209, 64, 114, 127, 61, 114, 125, 49, 106, 126, 58, 107, 125, 56, 107, 125, 211, 49, 101, 129, 4, 207, 45, 112, 129, 63, 115, 130, 30, 110, 131, 39, 110, 129, 57, 112, 133, 51, 112, 131, 54, 112, 133, 36, 110, 129, 4, 193, 28, 109, 127, 61, 115, 127, 52, 111, 127, 56, 111, 127, 194, 44, 110, 126, 34, 108, 127, 49, 111, 127, 37, 110, 127, 203, 61, 114, 132, 44, 108, 133, 28, 107, 129, 56, 110, 132, 52, 110, 131, 49, 110, 130, 204, 37, 108, 131, 34, 108, 130, 4, 197, 56, 107, 129, 63, 106, 126, 75, 110, 127, 68, 107, 126, 4, 198, 59, 112, 131, 54, 109, 133, 42, 106, 129, 47, 109, 135, 199, 27, 107, 130, 51, 107, 132, 35, 107, 129, 32, 107, 129, 4, 189, 57, 111, 127, 40, 106, 126, 45, 108, 127, 25, 104, 127, 49, 107, 127, 52, 107, 127, 33, 104, 126, 30, 104, 126, 200, 57, 110, 144, 40, 104, 140, 201, 25, 104, 141, 45, 107, 143, 49, 107, 146, 30, 104, 152, 33, 104, 148, 52, 104, 147, 4, 212, 55, 105, 127, 43, 103, 126, 46, 103, 126, 34, 102, 126, 39, 100, 127, 27, 103, 127, 51, 104, 126, 4, 192, 56, 107, 132, 42, 104, 129, 32, 102, 131, 39, 102, 134, 51, 102, 130, 24, 102, 130, 215, 63, 103, 127, 44, 102, 129, 56, 101, 128, 51, 100, 128, 4, 215, 22, 107, 145, 217, 38, 109, 151, 219, 44, 112, 152, 4, 191, 54, 113, 142, 4, 191, 53, 108, 126, 196, 53, 108, 132, 23, 105, 128, 39, 103, 133, 44, 105, 126, 198, 44, 103, 130, 218, 63, 103, 128, 44, 102, 128, 51, 102, 128, 56, 103, 128, 4, 218, 21, 107, 149, 220, 36, 107, 160, 4, 190, 42, 109, 146, 196, 52, 111, 148, 4, 199, 51, 107, 126, 205, 22, 103, 135, 209, 43, 104, 132, 37, 103, 134, 210, 51, 106, 132, 4, 203, 63, 102, 128, 43, 100, 129, 51, 99, 129, 204, 55, 99, 127, 4, 217, 49, 107, 149, 37, 103, 136, 33, 103, 136, 40, 104, 136, 4, 210, 33, 106, 129, 47, 111, 138, 30, 104, 128, 39, 107, 128, 4, 190, 40, 110, 126, 194, 45, 109, 137, 41, 106, 134, 195, 29, 104, 136, 36, 105, 135, 4, 189, 44, 109, 128, 28, 103, 127, 36, 103, 127, 42, 104, 127, 190, 32, 101, 127, 199, 44, 109, 130, 27, 105, 130, 36, 103, 131, 42, 104, 130, 32, 103, 130, 220, 63, 105, 127, 44, 101, 130, 56, 103, 128, 51, 104, 127, 4, 210, 28, 105, 133, 214, 30, 107, 129, 218, 32, 109, 135, 4, 192, 25, 109, 129, 44, 107, 129, 35, 105, 128, 41, 102, 130, 213, 63, 104, 127, 51, 103, 127, 44, 103, 129, 56, 103, 127, 4, 205, 27, 103, 132, 209, 29, 107, 129, 213, 32, 109, 132, 219, 23, 109, 131, 220, 28, 107, 131, 44, 107, 129, 40, 105, 130, 35, 105, 128, 4, 209, 64, 108, 127, 52, 104, 126, 210, 47, 104, 126, 55, 105, 127, 212, 63, 107, 127, 56, 107, 128, 213, 44, 105, 129, 51, 102, 127, 4, 204, 25, 104, 129, 209, 27, 106, 128, 214, 28, 107, 137, 4, 189, 22, 108, 129, 44, 107, 129, 37, 104, 128, 212, 63, 102, 127, 44, 102, 129, 56, 103, 127, 51, 102, 126, 4, 205, 23, 103, 138, 211, 25, 105, 131, 217, 28, 107, 134, 4, 193, 37, 105, 159, 43, 107, 160, 21, 105, 131, 200, 23, 103, 135, 209, 25, 102, 139, 4, 191, 27, 102, 132, 4, 192, 44, 102, 132, 8, 100, 129, 20, 100, 135, 36, 102, 131, 4, 190, 27, 101, 134, 198, 36, 102, 128, 204, 36, 103, 126, 210, 44, 102, 126, 216, 36, 100, 126, 4, 190, 36, 99, 130, 197, 27, 101, 127, 208, 39, 102, 128, 209, 36, 97, 129, 214, 44, 103, 126, 215, 39, 101, 129, 219, 44, 104, 129, 51, 103, 130, 4, 193, 56, 105, 126, 48, 103, 127, 198, 36, 103, 129, 44, 103, 128, 204, 51, 103, 132, 39, 102, 125, 209, 27, 104, 131, 39, 99, 125, 214, 20, 104, 125, 220, 44, 103, 128, 27, 104, 125, 4, 193, 36, 103, 125, 51, 105, 129, 198, 56, 104, 132, 36, 103, 129, 204, 63, 107, 126, 44, 104, 126, 209, 51, 103, 128, 36, 100, 125, 215, 56, 100, 133, 36, 102, 132, 4, 189, 44, 101, 126, 27, 101, 126, 200, 51, 103, 130, 36, 102, 129, 205, 39, 103, 129, 56, 104, 129, 210, 63, 105, 134, 211, 44, 103, 130, 216, 68, 107, 127, 48, 103, 128, 4, 189, 56, 103, 129, 36, 101, 129, 195, 63, 105, 136, 39, 100, 129, 200, 27, 105, 126, 202, 51, 97, 125, 208, 8, 106, 125, 20, 104, 125, 214, 56, 104, 134, 27, 104, 128, 220, 63, 104, 130, 36, 101, 129, 4, 193, 44, 104, 135, 194, 68, 103, 125, 195, 56, 105, 126, 197, 63, 106, 127, 199, 68, 106, 131, 203, 51, 106, 132, 206, 75, 113, 126, 212, 44, 101, 130, 214, 63, 101, 136, 219, 68, 104, 130, 36, 102, 132, 4, 192, 56, 101, 127, 27, 102, 126, 204, 51, 102, 132, 36, 101, 129, 209, 39, 103, 130, 210, 56, 104, 129, 214, 63, 104, 126, 215, 44, 102, 129, 220, 63, 105, 128, 48, 102, 128, 4, 193, 56, 105, 134, 194, 36, 101, 129, 199, 39, 103, 130, 200, 68, 109, 127, 201, 63, 102, 125, 206, 27, 105, 125, 208, 51, 102, 125, 210, 56, 105, 126, 212, 60, 104, 129, 216, 8, 103, 126, 20, 102, 127, 217, 68, 110, 125, 4, 194, 44, 103, 131, 27, 99, 127, 200, 51, 102, 133, 36, 101, 126, 205, 36, 101, 129, 206, 56, 102, 125, 211, 56, 104, 145, 44, 102, 127, 217, 36, 102, 125, 51, 101, 139, 4, 191, 36, 101, 131, 197, 44, 101, 126, 27, 101, 126, 208, 51, 104, 134, 209, 36, 101, 131, 215, 39, 103, 132, 217, 63, 110, 141, 60, 105, 126, 4, 191, 44, 101, 130, 51, 104, 128, 196, 48, 102, 128, 202, 36, 102, 129, 51, 104, 130, 207, 39, 105, 131, 208, 65, 113, 128, 56, 107, 131, 214, 27, 104, 125, 48, 107, 125, 218, 51, 105, 136, 220, 56, 106, 133, 4, 190, 60, 109, 131, 194, 17, 108, 128, 195, 67, 113, 126, 206, 36, 100, 130, 44, 102, 130, 212, 39, 102, 131, 213, 51, 101, 132, 218, 44, 100, 130, 56, 104, 126, 4, 192, 48, 101, 127, 56, 103, 138, 197, 39, 102, 130, 198, 51, 103, 132, 204, 44, 101, 125, 210, 36, 103, 126, 44, 102, 134, 219, 15, 106, 127, 4, 194, 27, 102, 138, 195, 48, 103, 125, 197, 51, 104, 126, 200, 56, 106, 129, 204, 65, 110, 125, 210, 36, 103, 129, 215, 44, 102, 125, 4, 189, 51, 105, 132, 36, 101, 125, 195, 36, 102, 132, 197, 63, 110, 126, 56, 103, 125, 203, 27, 100, 126, 206, 39, 97, 125, 207, 44, 104, 126, 209, 48, 104, 130, 214, 8, 103, 126, 20, 102, 128, 56, 108, 128, 4, 192, 27, 103, 130, 198, 36, 102, 126, 204, 56, 107, 127, 44, 103, 125, 36, 104, 127, 210, 56, 107, 130, 211, 44, 105, 126, 48, 100, 127, 216, 36, 102, 126, 217, 44, 100, 128, 4, 191, 36, 102, 132, 48, 101, 148, 197, 39, 103, 134, 27, 99, 127, 205, 19, 108, 127, 214, 36, 104, 131, 44, 104, 132, 220, 39, 104, 135, 4, 189, 51, 109, 147, 190, 46, 105, 128, 195, 44, 103, 125, 36, 100, 130, 200, 48, 105, 129, 206, 36, 103, 129, 44, 104, 129, 211, 39, 105, 131, 212, 53, 110, 136, 213, 46, 103, 127, 218, 36, 104, 125, 219, 44, 101, 125, 4, 190, 44, 105, 134, 192, 48, 106, 132, 196, 17, 106, 128, 197, 55, 110, 138, 207, 36, 103, 129, 44, 103, 128, 212, 39, 103, 130, 48, 103, 128, 218, 55, 104, 132, 44, 102, 130, 4, 192, 60, 107, 127, 48, 103, 126, 197, 39, 102, 129, 198, 48, 103, 138, 204, 44, 101, 125, 210, 36, 102, 126, 44, 102, 136, 219, 15, 106, 127, 4, 196, 44, 101, 138, 27, 105, 133, 202, 36, 105, 128, 204, 53, 110, 137, 210, 36, 101, 129, 48, 102, 126, 215, 56, 104, 128, 44, 102, 125, 4, 189, 36, 104, 125, 44, 101, 128, 195, 51, 108, 131, 196, 36, 103, 130, 203, 27, 103, 125, 39, 103, 127, 214, 44, 107, 132, 20, 102, 130, 8, 102, 127, 36, 104, 130, 4, 192, 39, 102, 129, 193, 27, 101, 127, 198, 51, 104, 129, 199, 36, 103, 125, 204, 44, 108, 127, 36, 104, 128, 210, 44, 105, 126, 56, 104, 127, 216, 44, 99, 128, 36, 98, 125, 4, 189, 51, 103, 128, 190, 36, 102, 130, 196, 39, 100, 125, 27, 100, 127, 208, 27, 103, 134, 215, 36, 104, 127, 217, 43, 110, 130, 4, 192, 36, 102, 126, 39, 103, 127, 197, 51, 103, 132, 48, 104, 127, 202, 36, 103, 134, 203, 39, 103, 130, 208, 41, 110, 130, 215, 27, 106, 125, 4, 190, 8, 104, 134, 193, 20, 105, 133, 194, 37, 107, 131, 41, 108, 133, 46, 106, 134, 197, 51, 105, 143, 208, 27, 103, 129, 214, 37, 104, 128, 215, 48, 104, 129, 219, 46, 105, 128, 220, 41, 102, 125, 4, 191, 51, 107, 127, 195, 41, 106, 126, 37, 105, 128, 199, 54, 111, 128, 41, 105, 127, 203, 46, 107, 128, 53, 111, 126, 207, 45, 106, 130, 209, 60, 111, 130, 214, 41, 101, 129, 53, 103, 130, 218, 61, 106, 128, 45, 100, 127, 4, 190, 60, 106, 129, 51, 103, 126, 193, 65, 106, 126, 57, 105, 125, 197, 53, 105, 125, 200, 58, 109, 129, 201, 54, 106, 128, 37, 106, 128, 205, 41, 102, 127, 53, 105, 127, 210, 46, 103, 129, 58, 108, 129, 214, 41, 104, 129, 215, 53, 102, 129, 220, 60, 104, 127, 46, 101, 126, 4, 192, 58, 103, 130, 53, 103, 125, 195, 65, 105, 126, 199, 53, 104, 125, 203, 15, 103, 127, 55, 104, 128, 206, 27, 106, 125, 207, 53, 105, 132, 211, 60, 106, 127, 43, 112, 125, 212, 37, 109, 125, 215, 48, 102, 125, 220, 27, 105, 128, 48, 103, 127, 4, 191, 46, 105, 132, 36, 105, 128, 195, 53, 103, 129, 196, 37, 107, 126, 199, 43, 103, 130, 203, 41, 111, 125, 204, 48, 103, 128, 208, 46, 103, 125, 212, 8, 104, 129, 215, 37, 107, 129, 41, 108, 131, 216, 20, 106, 128, 46, 109, 132, 218, 51, 108, 137, 4, 195, 27, 95, 127, 197, 37, 106, 127, 198, 48, 106, 128, 201, 41, 104, 125, 202, 46, 106, 128, 206, 51, 108, 126, 209, 37, 106, 128, 41, 107, 125, 212, 41, 106, 127, 54, 112, 128, 216, 46, 109, 129, 53, 112, 126, 4, 189, 45, 108, 130, 190, 60, 113, 130, 195, 41, 104, 129, 53, 104, 131, 200, 45, 103, 127, 61, 107, 128, 203, 60, 108, 128, 51, 103, 126, 207, 65, 108, 127, 57, 105, 125, 210, 53, 108, 126, 214, 58, 110, 130, 37, 104, 129, 54, 105, 128, 219, 41, 103, 128, 53, 106, 128, 4, 191, 46, 103, 128, 192, 58, 108, 130, 197, 41, 102, 135, 53, 104, 125, 203, 46, 102, 130, 204, 67, 107, 130, 210, 65, 105, 130, 53, 105, 125, 213, 72, 108, 127, 217, 60, 107, 125, 220, 60, 106, 128, 4, 189, 15, 103, 127, 192, 27, 107, 125, 58, 108, 132, 197, 43, 110, 126, 65, 106, 127, 37, 109, 125, 202, 53, 104, 125, 205, 27, 104, 129, 55, 104, 127, 209, 36, 105, 128, 53, 105, 131, 213, 60, 101, 128, 37, 106, 125, 218, 48, 103, 132, 4, 191, 44, 111, 125, 192, 53, 104, 129, 198, 51, 104, 125, 205, 8, 103, 128, 208, 44, 111, 128, 20, 105, 127, 37, 103, 126, 42, 104, 128, 216, 27, 102, 128, 4, 189, 32, 103, 129, 193, 37, 105, 127, 198, 51, 110, 126, 39, 105, 128, 201, 32, 104, 127, 205, 27, 105, 127, 208, 20, 109, 133, 213, 45, 111, 137, 36, 106, 126, 42, 108, 128, 218, 28, 105, 129, 4, 191, 36, 107, 127, 193, 52, 111, 142, 196, 40, 112, 128, 201, 48, 107, 126, 204, 42, 112, 125, 208, 36, 106, 125, 211, 26, 106, 125, 46, 110, 127, 216, 20, 109, 127, 8, 108, 126, 217, 46, 112, 141, 44, 110, 140, 39, 106, 128, 4, 191, 29, 105, 127, 194, 34, 107, 127, 197, 39, 106, 127, 201, 53, 113, 128, 41, 108, 127, 204, 34, 106, 127, 207, 29, 108, 127, 211, 20, 107, 134, 22, 105, 125, 215, 47, 112, 135, 38, 111, 125, 44, 111, 129, 220, 28, 110, 129, 4, 192, 38, 110, 126, 194, 54, 114, 140, 197, 42, 114, 128, 201, 50, 108, 126, 204, 44, 112, 125, 208, 38, 108, 125, 212, 28, 108, 125, 48, 112, 127, 217, 8, 111, 126, 20, 111, 127, 218, 48, 114, 140, 46, 112, 140, 41, 110, 130, 4, 192, 29, 104, 126, 195, 36, 108, 127, 198, 41, 110, 127, 201, 55, 114, 128, 43, 111, 127, 205, 36, 104, 126, 34, 102, 125, 208, 29, 110, 126, 211, 20, 112, 132, 215, 49, 113, 133, 40, 113, 125, 46, 112, 130, 219, 28, 114, 128, 4, 191, 37, 112, 125, 192, 56, 114, 136, 195, 44, 116, 126, 199, 52, 112, 125, 203, 46, 116, 125, 206, 37, 114, 125, 211, 28, 114, 125, 50, 117, 127, 218, 8, 116, 127, 20, 116, 127, 219, 47, 114, 130, 39, 115, 128, 50, 116, 129, 44, 112, 129, 4, 192, 27, 111, 126, 194, 35, 111, 125, 196, 38, 113, 125, 199, 41, 111, 127, 201, 44, 111, 128, 205, 50, 115, 127, 206, 65, 117, 125, 208, 44, 108, 126, 210, 41, 111, 125, 213, 35, 112, 125, 215, 27, 112, 125, 216, 51, 113, 127, 218, 39, 114, 126, 219, 44, 111, 126, 4, 189, 51, 112, 126, 190, 12, 116, 125, 24, 116, 125, 56, 117, 125, 196, 32, 110, 127, 198, 39, 112, 126, 200, 44, 114, 125, 203, 44, 114, 129, 207, 51, 114, 127, 208, 63, 116, 125, 211, 44, 111, 125, 215, 41, 105, 125, 216, 55, 114, 125, 53, 113, 125, 39, 103, 125, 220, 32, 113, 125, 4, 193, 17, 114, 127, 55, 115, 141, 194, 48, 113, 129, 46, 109, 129, 199, 36, 111, 137, 203, 39, 112, 128, 205, 60, 101, 126, 206, 46, 113, 127, 210, 60, 115, 127, 48, 111, 127, 213, 39, 110, 128, 217, 36, 109, 127, 220, 29, 111, 125, 4, 193, 22, 113, 126, 53, 114, 134, 194, 49, 112, 129, 44, 111, 126, 198, 34, 112, 141, 203, 37, 110, 132, 61, 115, 126, 207, 44, 110, 127, 210, 49, 111, 127, 213, 41, 111, 129, 217, 36, 111, 128, 51, 114, 126, 4, 189, 34, 111, 125, 193, 51, 113, 142, 43, 112, 129, 49, 113, 142, 197, 22, 112, 129, 202, 27, 111, 128, 205, 34, 111, 125, 209, 43, 111, 127, 58, 114, 127, 213, 36, 111, 127, 216, 37, 112, 128, 220, 27, 112, 125, 4, 192, 49, 114, 129, 42, 113, 136, 44, 111, 129, 196, 20, 114, 130, 202, 57, 115, 126, 32, 109, 125, 206, 32, 111, 128, 210, 42, 114, 126, 214, 32, 107, 133, 218, 48, 114, 127, 39, 111, 126, 44, 110, 126, 4, 190, 20, 112, 125, 195, 49, 114, 142, 40, 114, 133, 196, 44, 112, 137, 201, 13, 115, 129, 206, 25, 114, 125, 209, 32, 112, 130, 213, 40, 113, 126, 56, 115, 125, 217, 32, 109, 126, 220, 25, 111, 128, 4, 192, 13, 112, 125, 197, 48, 113, 136, 43, 112, 130, 41, 110, 128, 202, 19, 112, 129, 206, 55, 115, 127, 207, 31, 110, 125, 210, 31, 111, 128, 214, 41, 112, 127, 218, 31, 108, 134, 4, 191, 46, 111, 129, 40, 111, 127, 43, 110, 128, 195, 19, 110, 126, 202, 48, 110, 150, 203, 43, 105, 145, 39, 108, 139, 208, 12, 109, 128, 213, 24, 108, 125, 216, 31, 107, 130, 4, 190, 51, 110, 141, 39, 106, 128, 194, 32, 104, 129, 199, 31, 105, 130, 205, 24, 103, 126, 213, 46, 105, 139, 41, 105, 131, 44, 106, 139, 220, 25, 102, 130, 4, 193, 34, 104, 127, 194, 53, 111, 131, 198, 41, 106, 128, 202, 55, 114, 136, 46, 109, 126, 205, 41, 105, 130, 209, 56, 115, 128, 210, 45, 113, 126, 34, 109, 129, 214, 25, 110, 125, 4, 189, 57, 115, 148, 44, 111, 168, 53, 110, 147, 196, 26, 104, 130, 201, 34, 102, 128, 206, 41, 104, 128, 210, 58, 111, 173, 211, 46, 106, 127, 214, 41, 104, 130, 219, 52, 109, 127, 34, 106, 130, 4, 192, 26, 104, 126, 197, 51, 106, 169, 198, 49, 105, 168, 203, 15, 101, 128, 209, 27, 102, 125, 214, 37, 103, 126, 220, 43, 104, 149, 4, 194, 36, 103, 133, 203, 34, 102, 142, 219, 27, 102, 130, 220, 56, 106, 127, 4, 189, 44, 103, 128, 216, 56, 103, 132, 48, 102, 133, 44, 101, 133, 8, 99, 130, 217, 20, 99, 134, 4, 208, 27, 102, 142, 216, 36, 102, 126, 4, 190, 36, 102, 128, 195, 44, 103, 126, 202, 36, 101, 125, 208, 36, 102, 132, 216, 27, 102, 140, 4, 196, 15, 106, 126, 206, 44, 101, 133, 36, 102, 131, 213, 39, 103, 134, 214, 51, 108, 146, 46, 102, 126, 220, 36, 102, 129, 44, 102, 127, 4, 193, 48, 103, 130, 197, 36, 103, 128, 44, 105, 128, 203, 39, 103, 129, 53, 110, 133, 46, 105, 125, 208, 36, 104, 125, 209, 44, 104, 125, 212, 44, 104, 132, 214, 48, 107, 131, 217, 29, 106, 129, 17, 103, 126, 218, 55, 110, 135, 4, 194, 44, 102, 130, 195, 29, 99, 132, 198, 48, 102, 128, 199, 36, 101, 125, 203, 36, 104, 125, 55, 105, 131, 208, 60, 108, 126, 44, 102, 126, 213, 36, 102, 125, 214, 48, 102, 133, 219, 55, 103, 144, 36, 103, 126, 4, 193, 44, 101, 135, 200, 15, 109, 127, 208, 27, 105, 135, 211, 43, 109, 135, 218, 36, 103, 126, 219, 53, 110, 137, 4, 192, 36, 103, 128, 48, 104, 128, 197, 44, 103, 126, 198, 56, 105, 127, 203, 44, 101, 128, 204, 36, 100, 125, 210, 36, 102, 132, 51, 108, 133, 219, 41, 106, 127, 27, 103, 125, 220, 39, 101, 125, 4, 200, 20, 103, 130, 8, 103, 128, 201, 44, 108, 131, 202, 36, 104, 129, 211, 39, 96, 125, 27, 96, 125, 216, 51, 102, 130, 4, 190, 36, 104, 129, 44, 107, 125, 196, 44, 106, 126, 197, 56, 102, 125, 201, 36, 102, 125, 44, 102, 126, 206, 51, 101, 131, 207, 36, 100, 125, 212, 39, 100, 125, 27, 100, 125, 4, 190, 39, 101, 127, 36, 100, 129, 196, 44, 104, 126, 39, 100, 129, 200, 51, 105, 131, 44, 104, 129, 205, 56, 106, 126, 206, 48, 104, 127, 210, 36, 103, 128, 44, 101, 128, 215, 39, 103, 125, 51, 102, 131, 220, 27, 103, 130, 4, 189, 39, 101, 125, 193, 20, 106, 125, 198, 27, 103, 125, 44, 99, 127, 203, 36, 105, 125, 51, 104, 128, 208, 56, 105, 133, 36, 102, 126, 213, 63, 106, 126, 44, 102, 125, 218, 36, 103, 125, 51, 102, 128, 4, 191, 56, 105, 125, 36, 101, 127, 196, 44, 100, 125, 27, 102, 125, 206, 36, 102, 128, 51, 98, 129, 211, 56, 104, 129, 39, 103, 129, 216, 44, 103, 130, 63, 106, 133, 4, 190, 68, 106, 126, 48, 102, 128, 195, 36, 103, 131, 56, 103, 130, 202, 63, 104, 135, 39, 101, 135, 210, 51, 103, 126, 211, 27, 102, 125, 4, 197, 75, 109, 126, 51, 105, 127, 72, 105, 126, 68, 106, 125, 63, 104, 125, 39, 104, 127, 44, 102, 128, 48, 103, 127, 4, 210, 44, 105, 127, 75, 110, 131, 39, 106, 127, 48, 105, 127, 51, 107, 127, 72, 107, 129, 211, 63, 107, 129, 68, 107, 129, 4, 4, 199, 20, 102, 126, 200, 8, 103, 126, 220, 27, 103, 127, 4, 217, 75, 106, 170, 63, 99, 170, 51, 101, 170, 36, 102, 170, 44, 101, 170, 218, 60, 100, 170, 68, 100, 169, 39, 101, 169, 72, 97, 169]\n",
            "Encoding(num_tokens=4371, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with()"
      ],
      "metadata": {
        "id": "si7aVojHP2Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(encoded))\n",
        "print(len())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndzqqPlZPaQn",
        "outputId": "5fcfe3ed-0b12-434b-bdc7-972925e0be31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from miditok import REMI, TokenizerConfig\n",
        "from miditok.pytorch_data import DatasetMIDI, DataCollator, split_midis_for_training\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "\n",
        "# Creating a multitrack tokenizer, read the doc to explore all the parameters\n",
        "config = TokenizerConfig(num_velocities=16, use_chords=True, use_programs=True)\n",
        "tokenizer = REMI(config)\n",
        "\n",
        "# Train the tokenizer with Byte Pair Encoding (BPE)\n",
        "midi_paths = list(Path(\"/content/data/maestro-v2.0.0/selected_midi_files\").glob(\"**/*.mid\"))\n",
        "tokenizer.learn_bpe(vocab_size=30000, files_paths=midi_paths)\n",
        "tokenizer.save_params(Path(\"/content/data/maestro-v2.0.0/tokens_BPE\", \"tokenizer.json\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "Y3sUrQJ1fKfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split MIDIs into smaller chunks for training\n",
        "chunked = data_dir / \"chunked_data\"\n",
        "chunked.mkdir(parents=True, exist_ok=True)\n",
        "midi_paths = list(Path(\"/content/data/maestro-v2.0.0/selected_midi_files\").glob(\"**/*.midi\"))\n",
        "\n",
        "dataset_chunks_dir = Path(\"/content/data/maestro-v2.0.0/chunked_data\")\n",
        "split_midis_for_training(\n",
        "    files_paths=midi_paths,\n",
        "    tokenizer=tokenizer,\n",
        "    save_dir=dataset_chunks_dir,\n",
        "    max_seq_len=1024,\n",
        ")\n",
        "\n",
        "# Create a Dataset, a DataLoader and a collator to train a model\n",
        "dataset = DatasetMIDI(\n",
        "    files_paths=list(dataset_chunks_dir.glob(\"**/*.midi\")),\n",
        "    tokenizer=tokenizer,\n",
        "    max_seq_len=1024,\n",
        "    bos_token_id=tokenizer[\"BOS_None\"],\n",
        "    eos_token_id=tokenizer[\"EOS_None\"],\n",
        ")\n",
        "collator = DataCollator(tokenizer[\"PAD_None\"])\n",
        "dataloader = DataLoader(dataset, batch_size=64, collate_fn=collator)\n",
        "\n",
        "# Iterate over the dataloader to train a model\n",
        "for batch in dataloader:\n",
        "    print(\"Train your model on this batch...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KMz1CW0fbrX",
        "outputId": "0122172e-5ec9-4eae-ee40-30e89cf1d208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Splitting MIDIs (/content/data/maestro-v2.0.0/chunked_data): 100%|██████████| 101/101 [00:01<00:00, 89.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip show miditok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTG9Mp-5oe3N",
        "outputId": "59f8d7e4-c32c-4bf4-c7f3-47d6f2151de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: miditok\n",
            "Version: 3.0.2\n",
            "Summary: MIDI / symbolic music tokenizers for Deep Learning models.\n",
            "Home-page: \n",
            "Author: Nathan Fradet\n",
            "Author-email: \n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: huggingface-hub, numpy, symusic, tokenizers, tqdm\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ab hier alt"
      ],
      "metadata": {
        "id": "T5ec4jW8nqUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from miditok import REMI, TokenizerConfig\n",
        "from symusic import Score\n",
        "\n",
        "# Set up the tokenizer configuration\n",
        "config = TokenizerConfig(num_velocities=16, use_chords=True, use_programs=True)\n",
        "tokenizer = REMI()\n",
        "\n",
        "# Path to the folder containing MIDI files\n",
        "midi_files_dir = \"/content/data/maestro-v2.0.0/selected_midi_files\"\n",
        "\n",
        "# Path to the folder where token files will be saved\n",
        "tokens_dir = \"/content/data/maestro-v2.0.0/tokenized_midi_files\"\n",
        "output_path = os.path.join(data_dir, tokens_dir)\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "# Create the tokens folder if it doesn't exist\n",
        "os.makedirs(tokens_dir, exist_ok=True)\n",
        "\n",
        "# Iterate through each MIDI file in the folder\n",
        "for filename in os.listdir(midi_files_dir):\n",
        "    # Construct the full path to the MIDI file\n",
        "    midi_file_path = os.path.join(midi_files_dir, filename)\n",
        "\n",
        "    # Check if the item in the folder is a file (not a subdirectory)\n",
        "    if os.path.isfile(midi_file_path):\n",
        "        try:\n",
        "            # Load the MIDI file\n",
        "            midi = Score(midi_file_path)\n",
        "\n",
        "            # Tokenize the MIDI file\n",
        "            tokens = tokenizer(midi)\n",
        "\n",
        "            # Construct the path for the token file\n",
        "            tokens_file_path = os.path.join(tokens_dir, os.path.splitext(filename)[0] + \"_tokens.txt\")\n",
        "\n",
        "            # Save the tokens to the token file\n",
        "            with open(tokens_file_path, \"w\") as f:\n",
        "                f.write(str(tokens))\n",
        "\n",
        "            print(f\"Tokenization successful for {filename}. Tokens saved to {tokens_file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "    else:\n",
        "        print(f\"{filename} is not a file\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHmHFvsXqlup",
        "outputId": "ccd18d69-e7a8-49c8-98b5-126439fd0eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization successful for MIDI-Unprocessed_XP_15_R2_2004_01_ORIG_MID--AUDIO_15_R2_2004_02_Track02_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_15_R2_2004_01_ORIG_MID--AUDIO_15_R2_2004_02_Track02_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_11_R1_2004_03-04_ORIG_MID--AUDIO_11_R1_2004_04_Track04_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_11_R1_2004_03-04_ORIG_MID--AUDIO_11_R1_2004_04_Track04_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_19_R2_2004_01_ORIG_MID--AUDIO_19_R2_2004_02_Track02_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_19_R2_2004_01_ORIG_MID--AUDIO_19_R2_2004_02_Track02_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_SMF_17_R1_2004_01-03_ORIG_MID--AUDIO_17_R1_2004_02_Track02_wav--1.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_01-03_ORIG_MID--AUDIO_17_R1_2004_02_Track02_wav--1_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_01_R1_2004_01-02_ORIG_MID--AUDIO_01_R1_2004_03_Track03_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_01_R1_2004_01-02_ORIG_MID--AUDIO_01_R1_2004_03_Track03_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_14_R2_2004_01_ORIG_MID--AUDIO_14_R2_2004_04_Track04_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_14_R2_2004_01_ORIG_MID--AUDIO_14_R2_2004_04_Track04_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_06_R2_2004_01_ORIG_MID--AUDIO_06_R2_2004_02_Track02_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_06_R2_2004_01_ORIG_MID--AUDIO_06_R2_2004_02_Track02_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_18_R1_2004_01-02_ORIG_MID--AUDIO_18_R1_2004_02_Track02_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_18_R1_2004_01-02_ORIG_MID--AUDIO_18_R1_2004_02_Track02_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_SMF_16_R1_2004_01-08_ORIG_MID--AUDIO_16_R1_2004_02_Track02_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_SMF_16_R1_2004_01-08_ORIG_MID--AUDIO_16_R1_2004_02_Track02_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_06_R2_2004_01_ORIG_MID--AUDIO_06_R2_2004_03_Track03_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_06_R2_2004_01_ORIG_MID--AUDIO_06_R2_2004_03_Track03_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_14_R1_2004_04_ORIG_MID--AUDIO_14_R1_2004_06_Track06_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_14_R1_2004_04_ORIG_MID--AUDIO_14_R1_2004_06_Track06_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_SMF_17_R1_2004_01-02_ORIG_MID--AUDIO_20_R2_2004_04_Track04_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_01-02_ORIG_MID--AUDIO_20_R2_2004_04_Track04_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_SMF_13_01_2004_01-05_ORIG_MID--AUDIO_13_R1_2004_12_Track12_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_SMF_13_01_2004_01-05_ORIG_MID--AUDIO_13_R1_2004_12_Track12_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_19_R2_2004_01_ORIG_MID--AUDIO_19_R2_2004_01_Track01_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_19_R2_2004_01_ORIG_MID--AUDIO_19_R2_2004_01_Track01_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_14_R2_2004_01_ORIG_MID--AUDIO_14_R2_2004_02_Track02_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_14_R2_2004_01_ORIG_MID--AUDIO_14_R2_2004_02_Track02_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_09_R1_2004_01-02_ORIG_MID--AUDIO_09_R1_2004_03_Track03_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_09_R1_2004_01-02_ORIG_MID--AUDIO_09_R1_2004_03_Track03_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_04_R1_2004_03-05_ORIG_MID--AUDIO_04_R1_2004_05_Track05_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_04_R1_2004_03-05_ORIG_MID--AUDIO_04_R1_2004_05_Track05_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_14_R1_2004_04_ORIG_MID--AUDIO_14_R1_2004_04_Track04_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_14_R1_2004_04_ORIG_MID--AUDIO_14_R1_2004_04_Track04_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_11_R1_2004_01-02_ORIG_MID--AUDIO_11_R1_2004_01_Track01_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_11_R1_2004_01-02_ORIG_MID--AUDIO_11_R1_2004_01_Track01_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_SMF_17_R1_2004_01-02_ORIG_MID--AUDIO_20_R2_2004_06_Track06_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_01-02_ORIG_MID--AUDIO_20_R2_2004_06_Track06_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_02_Track02_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_02_Track02_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_SMF_22_R1_2004_01-04_ORIG_MID--AUDIO_22_R1_2004_05_Track05_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_SMF_22_R1_2004_01-04_ORIG_MID--AUDIO_22_R1_2004_05_Track05_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_16_R2_2004_01_ORIG_MID--AUDIO_16_R2_2004_02_Track02_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_16_R2_2004_01_ORIG_MID--AUDIO_16_R2_2004_02_Track02_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_18_R1_2004_01-02_ORIG_MID--AUDIO_18_R1_2004_05_Track05_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_18_R1_2004_01-02_ORIG_MID--AUDIO_18_R1_2004_05_Track05_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_21_R1_2004_02_ORIG_MID--AUDIO_21_R1_2004_03_Track03_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_21_R1_2004_02_ORIG_MID--AUDIO_21_R1_2004_03_Track03_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_19_R1_2004_01-02_ORIG_MID--AUDIO_19_R1_2004_02_Track02_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_19_R1_2004_01-02_ORIG_MID--AUDIO_19_R1_2004_02_Track02_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_04_R1_2004_03-05_ORIG_MID--AUDIO_04_R1_2004_04_Track04_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_04_R1_2004_03-05_ORIG_MID--AUDIO_04_R1_2004_04_Track04_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_SMF_17_R1_2004_01-02_ORIG_MID--AUDIO_20_R2_2004_02_Track02_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_01-02_ORIG_MID--AUDIO_20_R2_2004_02_Track02_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_17_R2_2004_01_ORIG_MID--AUDIO_17_R2_2004_04_Track04_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_17_R2_2004_01_ORIG_MID--AUDIO_17_R2_2004_04_Track04_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_15_R2_2004_01_ORIG_MID--AUDIO_15_R2_2004_03_Track03_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_15_R2_2004_01_ORIG_MID--AUDIO_15_R2_2004_03_Track03_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_22_R2_2004_01_ORIG_MID--AUDIO_22_R2_2004_03_Track03_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_22_R2_2004_01_ORIG_MID--AUDIO_22_R2_2004_03_Track03_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_SMF_05_R1_2004_02-03_ORIG_MID--AUDIO_05_R1_2004_06_Track06_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_SMF_05_R1_2004_02-03_ORIG_MID--AUDIO_05_R1_2004_06_Track06_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_SMF_17_R1_2004_01-03_ORIG_MID--AUDIO_17_R1_2004_03_Track03_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_SMF_17_R1_2004_01-03_ORIG_MID--AUDIO_17_R1_2004_03_Track03_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_SMF_07_R1_2004_01_ORIG_MID--AUDIO_07_R1_2004_02_Track02_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_SMF_07_R1_2004_01_ORIG_MID--AUDIO_07_R1_2004_02_Track02_wav_tokens.txt\n",
            "Tokenization successful for MIDI-Unprocessed_XP_09_R1_2004_05_ORIG_MID--AUDIO_09_R1_2004_06_Track06_wav.midi. Tokens saved to /content/data/maestro-v2.0.0/tokenized_midi_files/MIDI-Unprocessed_XP_09_R1_2004_05_ORIG_MID--AUDIO_09_R1_2004_06_Track06_wav_tokens.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from miditok import REMI, TokSequence\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "\n",
        "def midi_valid(midi) -> bool:\n",
        "    if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
        "        return False  # time signature different from 4/*, 4 beats per bar\n",
        "    if midi.max_tick < 10 * midi.ticks_per_beat:\n",
        "        return False  # this MIDI is too short\n",
        "    return True\n",
        "\n",
        "# Paths to the MIDI files paths to where the tokens will be saved\n",
        "path_midi_files = '/content/data/maestro-v2.0.0/selected_midi_files'\n",
        "path_tokens_noBPE = '/content/data/maestro-v2.0.0/tokenized_midi_files'\n",
        "path_tokens_BPE = 'data/tokens_small_BPE/'\n",
        "\n",
        "if not os.path.exists(path_tokens_noBPE):\n",
        "    os.makedirs(path_tokens_noBPE)\n",
        "\n",
        "if not os.path.exists(path_tokens_BPE):\n",
        "    os.makedirs(path_tokens_BPE)\n",
        "\n",
        "\n",
        "# Creates the tokenizer and list the file paths\n",
        "tokenizer = REMI()\n",
        "midi_paths = list(Path(path_midi_files).glob('**/*.mid*'))\n",
        "\n",
        "# Converts MIDI files to tokens saved as JSON files\n",
        "tokenizer.tokenize_midi_dataset(\n",
        "    midi_paths,\n",
        "    Path(path_tokens_noBPE),\n",
        "    midi_valid\n",
        ")\n",
        "\n",
        "token_paths = list(Path('/content/data/tokens_small_noBPE').glob('**/*.json'))\n",
        "\n",
        "token_paths = [str(path) for path in token_paths]\n",
        "\n",
        "# Learns the vocabulary with BPE\n",
        "tokenizer.learn_bpe(\n",
        "    vocab_size=500,\n",
        "    iterator = token_paths,\n",
        "    out_dir=Path('/content/data/tokens_small_BPE'),\n",
        ")\n",
        "\n",
        "tokens = tokenizer.load_tokens(token_paths[0])\n",
        "tokens = TokSequence(ids=tokens)\n",
        "tokens_with_bpe = tokenizer.apply_bpe(tokens)\n",
        "tokens_no_bpe = tokenizer.decode_bpe(deepcopy(tokens_with_bpe))\n",
        "\n",
        "# Converts the tokenized musics into tokens with BPE\n",
        "tokenizer.apply_bpe_to_dataset(Path('/content/data/tokens_small_noBPE'), Path('data/tokens_small_BPE/'))\n",
        "\n",
        "# Opens tokens, apply BPE on them, and decode BPE back\n",
        "tokens = tokenizer.load_tokens(token_paths[0])\n",
        "#tokens = TokSequence(ids=tokens)\n",
        "tokens_with_bpe = tokenizer.apply_bpe(deepcopy(tokens))  # copy as the method is inplace\n",
        "#tokens_no_bpe = tokenizer.decode_bpe(deepcopy(tokens_with_bpe))\n",
        "\n",
        "# Converts the tokenized musics into tokens with BPE\n",
        "tokenizer.apply_bpe_to_dataset(Path('/content/data/tokens_small_noBPE'), Path('/content/data/tokens_small_BPE'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "3vOqw5hVpdjL",
        "outputId": "f98d3679-c1e8-4385-913e-7a4a6da26bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokenizing MIDIs (maestro-v2.0.0/tokenized_midi_files): 100%|██████████| 101/101 [00:11<00:00,  8.54it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b1c3d0cf5c2d>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mtokens_with_bpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_bpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "class BPE:\n",
        "    def __init__(self, vocab_size=1000):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.vocab = {}\n",
        "\n",
        "    def train_from_files(self, corpus_dir, num_iters=10):\n",
        "        # Initialize vocabulary with characters\n",
        "        tokens = Counter()\n",
        "        for filename in os.listdir(corpus_dir):\n",
        "            with open(os.path.join(corpus_dir, filename), 'r', encoding='utf-8') as file:\n",
        "                text = file.read()\n",
        "                tokens.update(text)\n",
        "\n",
        "        self.vocab = {token: count for token, count in tokens.items() if count > 0}\n",
        "\n",
        "        for i in range(num_iters):\n",
        "            pairs = self._get_stats()\n",
        "            if not pairs:\n",
        "                break\n",
        "\n",
        "            best_pair = max(pairs, key=pairs.get)\n",
        "            self._merge_vocab(best_pair)\n",
        "\n",
        "    def _get_stats(self):\n",
        "        pairs = Counter()\n",
        "        for word, freq in self.vocab.items():\n",
        "            symbols = word.split()\n",
        "            for i in range(len(symbols) - 1):\n",
        "                pair = (symbols[i], symbols[i + 1])\n",
        "                pairs[pair] += freq\n",
        "        return pairs\n",
        "\n",
        "    def _merge_vocab(self, pair):\n",
        "        new_vocab = {}\n",
        "        bigram = ' '.join(pair)\n",
        "        replacement = ''.join(pair)\n",
        "\n",
        "        for word in self.vocab:\n",
        "            new_word = word.replace(bigram, replacement)\n",
        "            new_vocab[new_word] = self.vocab[word]\n",
        "        self.vocab = new_vocab\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        tokens = text.split()\n",
        "        encoded_tokens = []\n",
        "        for token in tokens:\n",
        "            if token in self.vocab:\n",
        "                encoded_tokens.append(token)\n",
        "            else:\n",
        "                encoded_tokens.extend(self._split_token(token))\n",
        "        return encoded_tokens\n",
        "\n",
        "    def _split_token(self, token):\n",
        "        if len(token) == 1:\n",
        "            return [token]\n",
        "        pairs = [(token[i], token[i+1]) for i in range(len(token) - 1)]\n",
        "        split_tokens = []\n",
        "        for pair in pairs:\n",
        "            if pair in self.vocab:\n",
        "                split_tokens.append(''.join(pair))\n",
        "            else:\n",
        "                split_tokens.extend(pair)\n",
        "        return split_tokens\n",
        "\n",
        "# Example usage:\n",
        "corpus_dir = \"/content/data/maestro-v2.0.0/tokenized_midi_files\"\n",
        "bpe = BPE()\n",
        "bpe.train_from_files(corpus_dir)\n",
        "encoded_tokens = bpe.tokenize(\"/content/data/maestro-v2.0.0/tokenized_midi_files\")\n",
        "print(encoded_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxZ6lKIS8qyB",
        "outputId": "d032406f-2435-4391-ab6e-d58450befa4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/', 'c', 'c', 'o', 'o', 'n', 'n', 't', 't', 'e', 'e', 'n', 'n', 't', 't', '/', '/', 'd', 'd', 'a', 'a', 't', 't', 'a', 'a', '/', '/', 'm', 'm', 'a', 'a', 'e', 'e', 's', 's', 't', 't', 'r', 'r', 'o', 'o', '-', '-', 'v', 'v', '2', '2', '.', '.', '0', '0', '.', '.', '0', '0', '/', '/', 't', 't', 'o', 'o', 'k', 'k', 'e', 'e', 'n', 'n', 'i', 'i', 'z', 'z', 'e', 'e', 'd', 'd', '_', '_', 'm', 'm', 'i', 'i', 'd', 'd', 'i', 'i', '_', '_', 'f', 'f', 'i', 'i', 'l', 'l', 'e', 'e', 's']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "class BPE:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "    def train_from_json_files(self, corpus_dir):\n",
        "        for filename in os.listdir(corpus_dir):\n",
        "            if filename.endswith('.json'):\n",
        "                with open(os.path.join(corpus_dir, filename), 'r', encoding='utf-8') as file:\n",
        "                    data = json.load(file)\n",
        "                    for item in data:\n",
        "                        text = item.get('text', '')  # Assuming each item has a 'text' key\n",
        "                        self.tokenizer.add_tokens(text)\n",
        "\n",
        "    def apply_bpe_encoding(self, text):\n",
        "        return self.tokenizer.encode(text).tokens\n",
        "\n",
        "# Example usage:\n",
        "corpus_dir = \"/content/data/maestro-v2.0.0/tokenized_midi_files\"\n",
        "bpe = BPE()\n",
        "bpe.train_from_json_files(corpus_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "SklMjipZ_SKC",
        "outputId": "85bd22e1-7177-4f80-f8e6-33c340b06b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'get'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-fa5353988d2f>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mcorpus_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/data/maestro-v2.0.0/tokenized_midi_files\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mbpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mbpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_from_json_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-fa5353988d2f>\u001b[0m in \u001b[0;36mtrain_from_json_files\u001b[0;34m(self, corpus_dir)\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming each item has a 'text' key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "class BPE:\n",
        "    def __init__(self, vocab_size=1000):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.vocab = {}\n",
        "\n",
        "    def train_from_files(self, corpus_dir, num_iters=10):\n",
        "        # Initialize vocabulary with characters\n",
        "        tokens = Counter()\n",
        "        for filename in os.listdir(corpus_dir):\n",
        "            with open(os.path.join(corpus_dir, filename), 'r') as file:\n",
        "                text = file.read()\n",
        "                tokens.update(text.split())\n",
        "\n",
        "        self.vocab = {token: count for token, count in tokens.items() if count > 0}\n",
        "\n",
        "        for i in range(num_iters):\n",
        "            pairs = self._get_stats()\n",
        "            if not pairs:\n",
        "                break\n",
        "\n",
        "            best_pair = max(pairs, key=pairs.get)\n",
        "            self._merge_vocab(best_pair)\n",
        "\n",
        "    def tokenize_file(self, file_path):\n",
        "        with open(file_path, 'r') as file:\n",
        "            text = file.read()\n",
        "            return self.tokenize(text)\n",
        "\n",
        "    def _get_stats(self):\n",
        "        pairs = Counter()\n",
        "        for word, freq in self.vocab.items():\n",
        "            symbols = word.split()\n",
        "            for i in range(len(symbols) - 1):\n",
        "                pair = (symbols[i], symbols[i + 1])\n",
        "                pairs[pair] += freq\n",
        "        return pairs\n",
        "\n",
        "    def _merge_vocab(self, pair):\n",
        "        new_vocab = {}\n",
        "        bigram = ' '.join(pair)\n",
        "        replacement = ''.join(pair)\n",
        "\n",
        "        for word in self.vocab:\n",
        "            new_word = word.replace(bigram, replacement)\n",
        "            new_vocab[new_word] = self.vocab[word]\n",
        "        self.vocab = new_vocab\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        tokens = text.split()\n",
        "        encoded_tokens = []\n",
        "        for token in tokens:\n",
        "            if token in self.vocab:\n",
        "                encoded_tokens.append(token)\n",
        "            else:\n",
        "                encoded_tokens.extend(self._split_token(token))\n",
        "        return encoded_tokens\n",
        "\n",
        "    def _split_token(self, token):\n",
        "        if len(token) == 1:\n",
        "            return [token]\n",
        "        pairs = [(token[i], token[i+1]) for i in range(len(token) - 1)]\n",
        "        split_tokens = []\n",
        "        for pair in pairs:\n",
        "            if pair in self.vocab:\n",
        "                split_tokens.append(''.join(pair))\n",
        "            else:\n",
        "                split_tokens.extend(pair)\n",
        "        return split_tokens\n",
        "\n",
        "# Example usage:\n",
        "corpus_dir = \"/content/data/maestro-v2.0.0/tokenized_midi_files\"\n",
        "bpe = BPE()\n",
        "bpe.train_from_files(corpus_dir)\n",
        "encoded_tokens = bpe.tokenize_file(os.path.join(corpus_dir, \"filename.txt\"))\n",
        "print(encoded_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "38i-FoUe9x4m",
        "outputId": "64a85660-76ae-4a9d-ebaa-da2faa95bb57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/data/maestro-v2.0.0/tokenized_midi_files/filename.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9672e3d11b5d>\u001b[0m in \u001b[0;36m<cell line: 77>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mbpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mbpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_from_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mencoded_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"filename.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-9672e3d11b5d>\u001b[0m in \u001b[0;36mtokenize_file\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/maestro-v2.0.0/tokenized_midi_files/filename.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "# Step 1: Load tokenized data\n",
        "tokenized_data = '/content/data/tokens_small_noBPE'  # Your tokenized data\n",
        "\n",
        "# Step 2: Learn BPE encoding\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "tokenizer.train_from_iterator(tokenized_data)\n",
        "\n",
        "# Step 3: Apply BPE encoding\n",
        "bpe_encoded_data = [tokenizer.encode(sequence).tokens for sequence in tokenized_data]\n",
        "\n",
        "print(bpe_encoded_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DimLi-Zzt5QV",
        "outputId": "d43c5bf1-ece3-4156-850f-0cfeabbcbd78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['/'], ['c'], ['o'], ['n'], ['t'], ['e'], ['n'], ['t'], ['/'], ['d'], ['a'], ['t'], ['a'], ['/'], ['t'], ['o'], ['k'], ['e'], ['n'], ['s'], ['_'], ['s'], ['m'], ['a'], ['l'], ['l'], ['_'], ['n'], ['o'], ['B'], ['P'], ['E']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data = Path('/content/data/tokens_small_noBPE')  # Your tokenized data\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "tokenizer.train_from_iterator(tokenized_data)\n",
        "\n",
        "bpe_encoded_data = [tokenizer.encode(sequence).tokens for sequence in tokenized_data]\n",
        "\n",
        "\n",
        "print(bpe_encoded_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "wvrz1AB02qQC",
        "outputId": "1374c6e1-91dd-43e4-dd02-df0e861a14a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'PosixPath' object is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-3400c6e7c35d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteLevelBPETokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_from_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbpe_encoded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tokenizers/implementations/byte_level_bpe.py\u001b[0m in \u001b[0;36mtrain_from_iterator\u001b[0;34m(self, iterator, vocab_size, min_frequency, show_progress, special_tokens, length)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0minitial_alphabet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_tokenizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteLevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         )\n\u001b[0;32m--> 118\u001b[0;31m         self._tokenizer.train_from_iterator(\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'PosixPath' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def midi_valid(midi) -> bool:\n",
        "    if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
        "        return False  # time signature different from 4/*, 4 beats per bar\n",
        "    if midi.max_tick < 10 * midi.ticks_per_beat:\n",
        "        return False  # this MIDI is too short\n",
        "    return True\n",
        "\n",
        "# Paths to the MIDI files paths to where the tokens will be saved\n",
        "path_midi_files = '/content/data/maestro-v2.0.0/selected_midi_files'\n",
        "path_tokens_noBPE = 'data/tokens_small_noBPE/'\n",
        "path_tokens_BPE = 'data/tokens_small_BPE/'\n",
        "\n",
        "if not os.path.exists(path_tokens_noBPE):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "\n",
        "# Creates the tokenizer and list the file paths\n",
        "tokenizer = REMI()\n",
        "midi_paths = list(Path(path_midi_files).glob('**/*.mid*'))\n",
        "\n",
        "# Converts MIDI files to tokens saved as JSON files\n",
        "tokenizer.tokenize_midi_dataset(\n",
        "    midi_paths,\n",
        "    Path(path_tokens_noBPE),\n",
        "    midi_valid\n",
        ")\n",
        "\n",
        "# Learns the vocabulary with BPE\n",
        "tokenizer.learn_bpe(\n",
        "    500,\n",
        "    midi_paths,\n",
        "    files_paths=path_tokens_noBPE,\n",
        ")\n",
        "# Applies the learned BPE to the non-BPE tokens\n",
        "tokenizer.apply_bpe_to_dataset(Path(path_tokens_noBPE), Path(path_tokens_BPE))"
      ],
      "metadata": {
        "id": "OfAglI94rMmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from miditok import REMI, TokSequence\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "\n",
        "tokenizer = REMI()  # using defaults parameters (constants.py)\n",
        "token_paths = list(Path('/content/data/tokens_small_noBPE').glob('**/*.json'))\n",
        "\n",
        "token_paths = [str(path) for path in token_paths]\n",
        "\n",
        "# Learns the vocabulary with BPE\n",
        "tokenizer.learn_bpe(\n",
        "    vocab_size=500,\n",
        "    iterator = token_paths,\n",
        "    out_dir=Path('/content/data/tokens_small_BPE'),\n",
        ")\n",
        "\n",
        "# Opens tokens, apply BPE on them, and decode BPE back\n",
        "tokens = tokenizer.load_tokens(token_paths[0])\n",
        "tokens = TokSequence(ids=tokens)\n",
        "tokens_with_bpe = tokenizer.apply_bpe(deepcopy(tokens))  # copy as the method is inplace\n",
        "tokens_no_bpe = tokenizer.decode_bpe(deepcopy(tokens_with_bpe))\n",
        "\n",
        "# Converts the tokenized musics into tokens with BPE\n",
        "tokenizer.apply_bpe_to_dataset(Path('/content/data/tokens_small_noBPE'), Path('/content/data/tokens_small_BPE'))"
      ],
      "metadata": {
        "id": "sZvIPghuq6na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from miditok import REMI\n",
        "from pathlib import Path\n",
        "\n",
        "# Creates the tokenizer and list the file paths\n",
        "tokenizer = REMI()  # using defaults parameters (constants.py)\n",
        "midi_paths = list(Path(\"/content/data/maestro-v2.0.0/selected_midi_files\").glob(\"**/*.mid\"))\n",
        "\n",
        "# Builds the vocabulary with BPE\n",
        "output = tokenizer.learn_bpe(vocab_size=30000, files_paths=midi_paths)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADYW2J-OPhHj",
        "outputId": "18581d1b-9a26-4109-d42c-26cdb6e361e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from miditok import REMI\n",
        "from pathlib import Path\n",
        "\n",
        "# Creates the tokenizer and lists the file paths\n",
        "tokenizer = REMI()\n",
        "midi_paths = list(Path(\"/content/data/maestro-v2.0.0/selected_midi_files\").glob(\"**/*.mid\"))\n",
        "\n",
        "# Builds the vocabulary with BPE\n",
        "tokenizer.learn_bpe(vocab_size=30000, files_paths=midi_paths)\n",
        "\n",
        "# Create a new folder to save the tokenized data\n",
        "output_folder = Path(\"/content/data/BPE_tokenized_data\")\n",
        "output_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Tokenize and save the MIDI files\n",
        "for midi_path in midi_paths:\n",
        "    output_path = output_folder / midi_path.relative_to(\"/content/data/maestro-v2.0.0/selected_midi_files\").with_suffix(\".tokens\")\n",
        "    tokenizer.tokenize_file(midi_path, output_path)\n"
      ],
      "metadata": {
        "id": "dljKbc_sH513"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from miditok import REMI, bpe\n",
        "from pathlib import Path\n",
        "\n",
        "# Creates the tokenizer and list the file paths\n",
        "tokenizer = REMI()  # using defaults parameters (constants.py), with MASK tokens for pre-training\n",
        "paths = list(Path('/content/data/maestro-v2.0.0/selected_midi_files').glob('**/*.midi'))\n",
        "\n",
        "# A validation method to discard MIDIs we do not want\n",
        "# It can also be used for custom pre-processing, for instance if you want to merge\n",
        "# some tracks before tokenizing a MIDI file\n",
        "def midi_valid(midi) -> bool:\n",
        "    if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
        "        return False  # time signature different from 4/*, 4 beats per bar\n",
        "    if midi.max_tick < 10 * midi.ticks_per_beat:\n",
        "        return False  # this MIDI is too short\n",
        "    return True\n",
        "\n",
        "# Converts MIDI files to tokens saved as JSON files\n",
        "tokenizer.tokenize_midi_dataset(paths, '/content/data/BPE_tokenized_data', midi_valid)\n",
        "\n",
        "# Creates the tokenizer, bpe method takes a class and its constructor arguments as arguments\n",
        "tokenizer = bpe(REMI)  # as is, its exactly like a standard REMI tokenizer\n",
        "midi_paths = list(Path('/content/data/maestro-v2.0.0/selected_midi_files').glob('**/*.midi'))\n",
        "tokenizer.tokenize_midi_dataset(midi_paths, Path('/content/data/BPE_tokenized_data'))\n",
        "\n",
        "# Constructs the vocabulary with BPE\n",
        "tokenizer.bpe(tokens_path=Path('/content/data/BPE_tokenized_data'), vocab_size=500,\n",
        "              out_dir=Path('/content/data/BPE_tokenized_data'), files_lim=300)\n",
        "\n",
        "# Converts the tokenized musics into tokens with BPE\n",
        "tokenizer.apply_bpe_to_dataset(Path('/content/data/BPE_tokenized_data'), Path('/content/data/BPE_tokenized_data'))"
      ],
      "metadata": {
        "id": "q-LxbPuPKSzm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "fa5cec3f-6b62-42e7-b2dc-e1bc8c7775d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'bpe' from 'miditok' (/usr/local/lib/python3.10/dist-packages/miditok/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c2876e8f36e6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmiditok\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mREMI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Creates the tokenizer and list the file paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mREMI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# using defaults parameters (constants.py), with MASK tokens for pre-training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'bpe' from 'miditok' (/usr/local/lib/python3.10/dist-packages/miditok/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from miditok import REMI, TokenizerConfig, TokSequence\n",
        "from copy import deepcopy\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "tokenizer = REMI(TokenizerConfig(use_programs=True))\n",
        "paths_midis = list(Path(\"/content/data/maestro-v2.0.0/selected_midi_files\").glob('**/*.mid'))\n",
        "\n",
        "# Learns the vocabulary with BPE\n",
        "tokenizer.learn_bpe(\n",
        "    vocab_size= 500,\n",
        "    files_paths=paths_midis,\n",
        ")"
      ],
      "metadata": {
        "id": "Y6V8asgsRwio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import miditok\n",
        "\n",
        "data = list(Path('/content/data/maestro-v2.0.0/tokenized_midi_files'))\n",
        "miditok.MIDITokenizer.apply_bpe(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "EeBwIWXOUqCU",
        "outputId": "5780d942-5efd-4f61-cc0a-67e9124a90bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'PosixPath' object is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-01fcb592ca2a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmiditok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data/maestro-v2.0.0/tokenized_midi_files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmiditok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIDITokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_bpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'PosixPath' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0yr6VBhlVQzF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}